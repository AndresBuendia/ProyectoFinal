{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from binance.client import Client\n",
    "import requests\n",
    "import ta\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import GRU, LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from keras.models import load_model\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "              timestamp    close  next_close   predictions  \\\n",
      "709 2024-05-22 03:00:00  69943.8     69544.7  67996.062500   \n",
      "710 2024-05-22 04:00:00  69544.7     69865.0  67956.585938   \n",
      "711 2024-05-22 05:00:00  69865.0     69842.0  67946.367188   \n",
      "712 2024-05-22 06:00:00  69842.0     69712.7  68041.226562   \n",
      "713 2024-05-22 07:00:00  69712.7     70000.9  68070.742188   \n",
      "714 2024-05-22 08:00:00  70000.9     69990.7  68175.242188   \n",
      "715 2024-05-22 09:00:00  69990.7     70192.1  68266.023438   \n",
      "716 2024-05-22 10:00:00  70192.1     69811.6  68334.335938   \n",
      "717 2024-05-22 11:00:00  69811.6     69638.3  68329.406250   \n",
      "718 2024-05-22 12:00:00  69638.3     69788.3  68338.734375   \n",
      "719 2024-05-22 13:00:00  69788.3         NaN  68221.382812   \n",
      "\n",
      "     corrected_prediction      MAPE    signal    confidence  stop_loss  \\\n",
      "709          69644.161173  2.423815    Vender  4.862078e-03        NaN   \n",
      "710          69603.727772  2.423815   Comprar  6.982752e-04  68153.806   \n",
      "711          69593.261338  2.423815    Vender  2.498820e-03        NaN   \n",
      "712          69690.419929  2.423815    Vender  1.737479e-03        NaN   \n",
      "713          69720.650958  2.423815   Comprar  1.649396e-03  68318.446   \n",
      "714          69827.683844  2.423815    Vender  1.146193e-03        NaN   \n",
      "715          69920.665464  2.423815    Vender  9.468056e-07        NaN   \n",
      "716          69990.633732  2.423815    Vender  2.942147e-03        NaN   \n",
      "717          69985.584558  2.423815   Comprar  2.629058e-03  68415.368   \n",
      "718          69995.138780  2.423815   Comprar  3.398171e-03  68245.534   \n",
      "719          69874.942833  2.423815  Mantener           NaN        NaN   \n",
      "\n",
      "    accuracy  \n",
      "709     True  \n",
      "710     True  \n",
      "711     True  \n",
      "712     True  \n",
      "713     True  \n",
      "714     True  \n",
      "715    False  \n",
      "716     True  \n",
      "717    False  \n",
      "718     True  \n",
      "719      NaN  \n",
      "El porcentaje de acierto en las últimas 10 sesiones es: 80.00%\n"
     ]
    }
   ],
   "source": [
    "def fetch_latest_data_kraken(symbol, limit):\n",
    "    exchange = ccxt.kraken()\n",
    "    ohlcv = exchange.fetch_ohlcv(symbol, timeframe='1h', limit=limit)\n",
    "    data = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "    data.set_index('timestamp', inplace=True)\n",
    "    return data\n",
    "\n",
    "def initialize_support_resistance(df):\n",
    "    df['support'] = df['low'].rolling(window=30).min()\n",
    "    df['resistance'] = df['high'].rolling(window=30).max()\n",
    "    df['dynamic_support'] = df['low'].rolling(window=5).min()\n",
    "    df['dynamic_resistance'] = df['high'].rolling(window=5).max()\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df['sma_7'] = df['close'].rolling(window=7).mean()\n",
    "    df['ema_7'] = df['close'].ewm(span=7, adjust=False).mean()\n",
    "    df['sma_14'] = df['close'].rolling(window=14).mean()\n",
    "    df['ema_14'] = df['close'].ewm(span=14, adjust=False).mean()\n",
    "    df['sma_21'] = df['close'].rolling(window=21).mean()\n",
    "    df['ema_21'] = df['close'].ewm(span=21, adjust=False).mean()\n",
    "    df['sma_28'] = df['close'].rolling(window=28).mean()\n",
    "    df['ema_28'] = df['close'].ewm(span=28, adjust=False).mean()\n",
    "    df['sma_50'] = df['close'].rolling(window=50).mean()\n",
    "    df['ema_50'] = df['close'].ewm(span=50, adjust=False).mean()\n",
    "    df['sma_100'] = df['close'].rolling(window=100).mean()\n",
    "    df['ema_100'] = df['close'].ewm(span=100, adjust=False).mean()\n",
    "    df['sma_200'] = df['close'].rolling(window=200).mean()\n",
    "    df['ema_200'] = df['close'].ewm(span=200, adjust=False).mean()\n",
    "    df['rsi_14'] = talib.RSI(df['close'], timeperiod=14)\n",
    "    df['macd'], df['macd_signal'], df['macd_diff'] = talib.MACD(df['close'])\n",
    "    df['willr'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['atr_14'] = talib.ATR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['adx'] = talib.ADX(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['cci'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['ichimoku_a'] = (talib.MIN(df['low'], timeperiod=9) + talib.MAX(df['high'], timeperiod=9)) / 2\n",
    "    df['ichimoku_b'] = (talib.MIN(df['low'], timeperiod=26) + talib.MAX(df['high'], timeperiod=26)) / 2\n",
    "    df['momentum_10'] = talib.MOM(df['close'], timeperiod=10)\n",
    "    df['momentum_14'] = talib.MOM(df['close'], timeperiod=14)\n",
    "    df['momentum_20'] = talib.MOM(df['close'], timeperiod=20)\n",
    "    df['momentum_30'] = talib.MOM(df['close'], timeperiod=30)\n",
    "    df['keltner_hband'] = talib.MA((df['high'] + df['low'] + df['close']) / 3 + 2 * df['atr_14'], timeperiod=10)\n",
    "    df['keltner_lband'] = talib.MA((df['high'] + df['low'] + df['close']) / 3 - 2 * df['atr_14'], timeperiod=10)\n",
    "    df['doji'] = talib.CDLDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['engulfing'] = talib.CDLENGULFING(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['hammer'] = talib.CDLHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['inverted_hammer'] = talib.CDLINVERTEDHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['hanging_man'] = talib.CDLHANGINGMAN(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['shooting_star'] = talib.CDLSHOOTINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['morning_star'] = talib.CDLMORNINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['evening_star'] = talib.CDLEVENINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['morning_doji_star'] = talib.CDLMORNINGDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['evening_doji_star'] = talib.CDLEVENINGDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['piercing_line'] = talib.CDLPIERCING(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['dark_cloud_cover'] = talib.CDLDARKCLOUDCOVER(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_white_soldiers'] = talib.CDL3WHITESOLDIERS(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_black_crows'] = talib.CDL3BLACKCROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_inside_up_down'] = talib.CDL3INSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_outside_up_down'] = talib.CDL3OUTSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_stars_in_the_south'] = talib.CDL3STARSINSOUTH(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_advancing_white_soldiers'] = talib.CDLADVANCEBLOCK(df['open'], df['high'], df['low'], df['close'])\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "def create_sequences(X, y, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        xs.append(X[i:i + seq_length])\n",
    "        ys.append(y[i + seq_length])\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "def trading_strategy(df, mape_threshold, buy_threshold, sell_threshold, stop_loss_percentage):\n",
    "    signals = []\n",
    "    confidences = []\n",
    "    stop_losses = []\n",
    "    for i in range(len(df) - 1):\n",
    "        if df['MAPE'].iloc[i] > mape_threshold:\n",
    "            signals.append('No hacer nada')\n",
    "            confidences.append(0)\n",
    "            stop_losses.append(np.nan)\n",
    "        else:\n",
    "            confidence = abs(df['corrected_prediction'].iloc[i + 1] - df['close'].iloc[i]) / df['close'].iloc[i]\n",
    "            confidences.append(confidence)\n",
    "            if df['corrected_prediction'].iloc[i + 1] > df['close'].iloc[i] + buy_threshold:\n",
    "                signals.append('Comprar')\n",
    "                stop_loss = df['close'].iloc[i] * (1 - stop_loss_percentage)\n",
    "                stop_losses.append(stop_loss)\n",
    "            elif df['corrected_prediction'].iloc[i + 1] < df['close'].iloc[i] - sell_threshold:\n",
    "                signals.append('Vender')\n",
    "                stop_losses.append(np.nan)\n",
    "            else:\n",
    "                signals.append('Mantener')\n",
    "                stop_losses.append(np.nan)\n",
    "    signals.append('Mantener')\n",
    "    confidences.append(np.nan)  # Ajustamos para evitar el 0 en la última predicción\n",
    "    stop_losses.append(np.nan)\n",
    "    return signals, confidences, stop_losses\n",
    "\n",
    "def evaluate_signal_accuracy(df):\n",
    "    accuracies = []\n",
    "    for i in range(len(df) - 1):\n",
    "        if df['signal'].iloc[i] == 'Comprar':\n",
    "            accuracies.append(df['next_close'].iloc[i] > df['close'].iloc[i])\n",
    "        elif df['signal'].iloc[i] == 'Vender':\n",
    "            accuracies.append(df['next_close'].iloc[i] < df['close'].iloc[i])\n",
    "        elif df['signal'].iloc[i] == 'Mantener':\n",
    "            accuracies.append(abs(df['next_close'].iloc[i] - df['close'].iloc[i]) < 0.01 * df['close'].iloc[i])\n",
    "        else:\n",
    "            accuracies.append(np.nan)\n",
    "    accuracies.append(np.nan)  # La última fila no tiene siguiente cierre para comparar\n",
    "    return accuracies\n",
    "\n",
    "def calculate_last_10_accuracy(df):\n",
    "    # Trabajar solo con las últimas 10 filas válidas excluyendo la última fila incompleta\n",
    "    df_last_10 = df.iloc[-11:-1] \n",
    "    total_signals = df_last_10['accuracy'].notna().sum()  # Total de señales válidas en las últimas 10 filas\n",
    "    correct_signals = (df_last_10['accuracy'] == True).sum()  # Número de señales correctas en las últimas 10 filas\n",
    "    return correct_signals / total_signals * 100 if total_signals > 0 else 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    st.title('Aplicación de Trading')\n",
    "    symbol = 'BTC/USDT'\n",
    "    limit = 60000\n",
    "    mape_threshold = 3  # Umbral de MAPE para no hacer nada\n",
    "    buy_threshold = 0.01  # Umbral para señal de compra\n",
    "    sell_threshold = 0.01  # Umbral para señal de venta\n",
    "    stop_loss_percentage = 0.02  # Stop-loss al 2% del precio de compra\n",
    "\n",
    "    df = fetch_latest_data_kraken(symbol, limit)\n",
    "    df = initialize_support_resistance(df)\n",
    "    df = preprocess_data(df)\n",
    "\n",
    "    df['next_close'] = df['close'].shift(-1)\n",
    "\n",
    "    features = df.drop(columns=['next_close'])\n",
    "    target = df['next_close']\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    target_scaled = scaler.fit_transform(target.values.reshape(-1, 1))\n",
    "\n",
    "    seq_length = 50\n",
    "    X, y = create_sequences(features_scaled, target_scaled, seq_length)\n",
    "\n",
    "    model_path = f'../models/best_model_BTCUSDT.keras'\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Asegúrate de que la forma de entrada es correcta para el modelo\n",
    "    if X.shape[1:] != model.input_shape[1:]:\n",
    "        st.error(f\"Shape mismatch: X shape is {X.shape[1:]}, model expects {model.input_shape[1:]}\")\n",
    "        return\n",
    "\n",
    "    # Predicción para las últimas 11 valores\n",
    "    predictions = []\n",
    "    for i in range(11):\n",
    "        input_data = X[-(11 - i)].reshape(1, seq_length, features_scaled.shape[1])\n",
    "        pred = model.predict(input_data)\n",
    "        predictions.append(scaler.inverse_transform(pred)[0][0])\n",
    "\n",
    "    # Agregar predicciones al DataFrame original para comparación\n",
    "    df['predictions'] = np.nan\n",
    "    df.iloc[-11:, df.columns.get_loc('predictions')] = predictions\n",
    "\n",
    "    # Calcular MAPE\n",
    "    actual = df['next_close'].iloc[-11:]\n",
    "    predicted = df['predictions'].iloc[-11:]\n",
    "    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "\n",
    "    # Ajuste de predicciones basado en MAPE\n",
    "    df['corrected_prediction'] = df['predictions'] * (1 + mape / 100)\n",
    "\n",
    "    # Generar señales de trading y stop-loss\n",
    "    df['MAPE'] = mape\n",
    "    df['signal'], df['confidence'], df['stop_loss'] = trading_strategy(df, mape_threshold, buy_threshold, sell_threshold, stop_loss_percentage)\n",
    "\n",
    "    # Evaluar la exactitud de las señales\n",
    "    df['accuracy'] = evaluate_signal_accuracy(df)\n",
    "\n",
    "    # Calcular la precisión global para las últimas 10 filas\n",
    "    last_10_accuracy = calculate_last_10_accuracy(df)\n",
    "\n",
    "    # Restablecer el índice para que 'timestamp' esté disponible como columna\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Mostrar la tabla en Streamlit\n",
    "    st.write(df[['timestamp', 'close', 'next_close', 'predictions', 'corrected_prediction', 'signal', 'confidence', 'stop_loss', 'accuracy']].tail(11))\n",
    "\n",
    "    # Mostrar señales de trading en Streamlit\n",
    "    st.write(\"Señales de Trading:\")\n",
    "    for index, row in df[['timestamp', 'signal', 'confidence', 'stop_loss', 'accuracy']].tail(11).iterrows():\n",
    "        st.write(f\"Timestamp: {row['timestamp']}, Señal: {row['signal']}, Confianza: {row['confidence']:.2f}, Stop-Loss: {row['stop_loss']}, Exactitud: {row['accuracy']}\")\n",
    "\n",
    "    # Mostrar precisión global y MAPE\n",
    "    st.write(f\"Precisión global de las señales en las últimas 10 sesiones: {last_10_accuracy:.2f}%\")\n",
    "    st.write(f\"Error Absoluto Medio Porcentual (MAPE): {mape:.2f}%\")\n",
    "\n",
    "    # Advertir si falta poco tiempo para el cierre de la hora\n",
    "    current_time = datetime.now()\n",
    "    if current_time.minute > 20:\n",
    "        st.warning(\"Faltan menos de 40 minutos para el cierre de la hora actual. Es mejor pedir información en la siguiente hora.\")\n",
    "\n",
    "    # Imprimir las últimas 11 sesiones con los datos relevantes\n",
    "    print(df[['timestamp', 'close', 'next_close', 'predictions', 'corrected_prediction', 'MAPE', 'signal', 'confidence', 'stop_loss', 'accuracy']].tail(11))\n",
    "\n",
    "    # Imprimir el porcentaje de acierto en las últimas 10 sesiones\n",
    "    print(f\"El porcentaje de acierto en las últimas 10 sesiones es: {last_10_accuracy:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 13:49:24.855967: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-22 13:49:24.889621: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-22 13:49:24.889669: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-22 13:49:24.890835: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-22 13:49:24.896699: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-22 13:49:24.897619: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-22 13:49:26.730048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-05-22 13:49:28.299 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/codespace/.local/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-05-22 13:49:28.300 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import ccxt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from keras.models import load_model\n",
    "from datetime import datetime\n",
    "\n",
    "# Definir las funciones necesarias\n",
    "def fetch_latest_data_kraken(symbol, limit):\n",
    "    exchange = ccxt.kraken()\n",
    "    ohlcv = exchange.fetch_ohlcv(symbol, timeframe='1h', limit=limit)\n",
    "    data = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "    data.set_index('timestamp', inplace=True)\n",
    "    return data\n",
    "\n",
    "def initialize_support_resistance(df):\n",
    "    df['support'] = df['low'].rolling(window=30).min()\n",
    "    df['resistance'] = df['high'].rolling(window=30).max()\n",
    "    df['dynamic_support'] = df['low'].rolling(window=5).min()\n",
    "    df['dynamic_resistance'] = df['high'].rolling(window=5).max()\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df['sma_7'] = df['close'].rolling(window=7).mean()\n",
    "    df['ema_7'] = df['close'].ewm(span=7, adjust=False).mean()\n",
    "    df['sma_14'] = df['close'].rolling(window=14).mean()\n",
    "    df['ema_14'] = df['close'].ewm(span=14, adjust=False).mean()\n",
    "    df['sma_21'] = df['close'].rolling(window=21).mean()\n",
    "    df['ema_21'] = df['close'].ewm(span=21, adjust=False).mean()\n",
    "    df['sma_28'] = df['close'].rolling(window=28).mean()\n",
    "    df['ema_28'] = df['close'].ewm(span=28, adjust=False).mean()\n",
    "    df['sma_50'] = df['close'].rolling(window=50).mean()\n",
    "    df['ema_50'] = df['close'].ewm(span=50, adjust=False).mean()\n",
    "    df['sma_100'] = df['close'].rolling(window=100).mean()\n",
    "    df['ema_100'] = df['close'].ewm(span=100, adjust=False).mean()\n",
    "    df['sma_200'] = df['close'].rolling(window=200).mean()\n",
    "    df['ema_200'] = df['close'].ewm(span=200, adjust=False).mean()\n",
    "    df['rsi_14'] = talib.RSI(df['close'], timeperiod=14)\n",
    "    df['macd'], df['macd_signal'], df['macd_diff'] = talib.MACD(df['close'])\n",
    "    df['willr'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['atr_14'] = talib.ATR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['adx'] = talib.ADX(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['cci'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['ichimoku_a'] = (talib.MIN(df['low'], timeperiod=9) + talib.MAX(df['high'], timeperiod=9)) / 2\n",
    "    df['ichimoku_b'] = (talib.MIN(df['low'], timeperiod=26) + talib.MAX(df['high'], timeperiod=26)) / 2\n",
    "    df['momentum_10'] = talib.MOM(df['close'], timeperiod=10)\n",
    "    df['momentum_14'] = talib.MOM(df['close'], timeperiod=14)\n",
    "    df['momentum_20'] = talib.MOM(df['close'], timeperiod=20)\n",
    "    df['momentum_30'] = talib.MOM(df['close'], timeperiod=30)\n",
    "    df['keltner_hband'] = talib.MA((df['high'] + df['low'] + df['close']) / 3 + 2 * df['atr_14'], timeperiod=10)\n",
    "    df['keltner_lband'] = talib.MA((df['high'] + df['low'] + df['close']) / 3 - 2 * df['atr_14'], timeperiod=10)\n",
    "    df['doji'] = talib.CDLDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['engulfing'] = talib.CDLENGULFING(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['hammer'] = talib.CDLHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['inverted_hammer'] = talib.CDLINVERTEDHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['hanging_man'] = talib.CDLHANGINGMAN(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['shooting_star'] = talib.CDLSHOOTINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['morning_star'] = talib.CDLMORNINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['evening_star'] = talib.CDLEVENINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['morning_doji_star'] = talib.CDLMORNINGDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['evening_doji_star'] = talib.CDLEVENINGDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['piercing_line'] = talib.CDLPIERCING(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['dark_cloud_cover'] = talib.CDLDARKCLOUDCOVER(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_white_soldiers'] = talib.CDL3WHITESOLDIERS(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_black_crows'] = talib.CDL3BLACKCROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_inside_up_down'] = talib.CDL3INSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_outside_up_down'] = talib.CDL3OUTSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_stars_in_the_south'] = talib.CDL3STARSINSOUTH(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_advancing_white_soldiers'] = talib.CDLADVANCEBLOCK(df['open'], df['high'], df['low'], df['close'])\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "def create_sequences(X, y, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        xs.append(X[i:i + seq_length])\n",
    "        ys.append(y[i + seq_length])\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "def trading_strategy(df, mape_threshold, buy_threshold, sell_threshold, stop_loss_percentage):\n",
    "    signals = []\n",
    "    confidences = []\n",
    "    stop_losses = []\n",
    "    for i in range(len(df) - 1):\n",
    "        if df['MAPE'].iloc[i] > mape_threshold:\n",
    "            signals.append('No hacer nada')\n",
    "            confidences.append(0)\n",
    "            stop_losses.append(np.nan)\n",
    "        else:\n",
    "            confidence = abs(df['corrected_prediction'].iloc[i + 1] - df['close'].iloc[i]) / df['close'].iloc[i]\n",
    "            confidences.append(confidence)\n",
    "            if df['corrected_prediction'].iloc[i + 1] > df['close'].iloc[i] + buy_threshold:\n",
    "                signals.append('Comprar')\n",
    "                stop_loss = df['close'].iloc[i] * (1 - stop_loss_percentage)\n",
    "                stop_losses.append(stop_loss)\n",
    "            elif df['corrected_prediction'].iloc[i + 1] < df['close'].iloc[i] - sell_threshold:\n",
    "                signals.append('Vender')\n",
    "                stop_losses.append(np.nan)\n",
    "            else:\n",
    "                signals.append('Mantener')\n",
    "                stop_losses.append(np.nan)\n",
    "    signals.append('Mantener')\n",
    "    confidences.append(np.nan)\n",
    "    stop_losses.append(np.nan)\n",
    "    return signals, confidences, stop_losses\n",
    "\n",
    "def evaluate_signal_accuracy(df):\n",
    "    accuracies = []\n",
    "    for i in range(len(df) - 1):\n",
    "        if df['signal'].iloc[i] == 'Comprar':\n",
    "            accuracies.append(df['next_close'].iloc[i] > df['close'].iloc[i])\n",
    "        elif df['signal'].iloc[i] == 'Vender':\n",
    "            accuracies.append(df['next_close'].iloc[i] < df['close'].iloc[i])\n",
    "        elif df['signal'].iloc[i] == 'Mantener':\n",
    "            accuracies.append(abs(df['next_close'].iloc[i] - df['close'].iloc[i]) < 0.01 * df['close'].iloc[i])\n",
    "        else:\n",
    "            accuracies.append(np.nan)\n",
    "    accuracies.append(np.nan)\n",
    "    return accuracies\n",
    "\n",
    "def calculate_last_10_accuracy(df):\n",
    "    df_last_10 = df.iloc[-11:-1]\n",
    "    total_signals = df_last_10['accuracy'].notna().sum()\n",
    "    correct_signals = (df_last_10['accuracy'] == True).sum()\n",
    "    return correct_signals / total_signals * 100 if total_signals > 0 else 0\n",
    "\n",
    "# Interfaz de Streamlit\n",
    "def main():\n",
    "    st.title('Aplicación de Trading para Criptomonedas')\n",
    "    st.sidebar.header('Parámetros')\n",
    "    \n",
    "    crypto_symbol = st.sidebar.selectbox('Selecciona la criptomoneda', ['BTC/USDT', 'ETH/USDT', 'XRP/USDT', 'LTC/USDT'])\n",
    "    limit = st.sidebar.number_input('Número de registros (60000 recomendado)', min_value=1000, max_value=100000, value=60000)\n",
    "    mape_threshold = st.sidebar.slider('Umbral de MAPE (%)', 0, 10, 3)\n",
    "    buy_threshold = st.sidebar.slider('Umbral de compra (%)', 0.0, 5.0, 0.01)\n",
    "    sell_threshold = st.sidebar.slider('Umbral de venta (%)', 0.0, 5.0, 0.01)\n",
    "    stop_loss_percentage = st.sidebar.slider('Stop-loss (%)', 0.0, 10.0, 2.0)\n",
    "    seq_length = st.sidebar.slider('Longitud de la secuencia', 1, 100, 50)\n",
    "\n",
    "    if st.sidebar.button('Ejecutar Predicción'):\n",
    "        df = fetch_latest_data_kraken(crypto_symbol, limit)\n",
    "        df = initialize_support_resistance(df)\n",
    "        df = preprocess_data(df)\n",
    "\n",
    "        df['next_close'] = df['close'].shift(-1)\n",
    "\n",
    "        features = df.drop(columns=['next_close'])\n",
    "        target = df['next_close']\n",
    "\n",
    "        scaler = RobustScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "        target_scaled = scaler.fit_transform(target.values.reshape(-1, 1))\n",
    "\n",
    "        X, y = create_sequences(features_scaled, target_scaled, seq_length)\n",
    "\n",
    "        model_path = f'../models/best_model_{crypto_symbol.replace(\"/\", \"\")}.keras'\n",
    "        model = load_model(model_path)\n",
    "\n",
    "        if X.shape[1:] != model.input_shape[1:]:\n",
    "            st.error(f\"Shape mismatch: X shape is {X.shape[1:]}, model expects {model.input_shape[1:]}\")\n",
    "            return\n",
    "\n",
    "        predictions = []\n",
    "        for i in range(11):\n",
    "            input_data = X[-(11 - i)].reshape(1, seq_length, features_scaled.shape[1])\n",
    "            pred = model.predict(input_data)\n",
    "            predictions.append(scaler.inverse_transform(pred)[0][0])\n",
    "\n",
    "        df['predictions'] = np.nan\n",
    "        df.iloc[-11:, df.columns.get_loc('predictions')] = predictions\n",
    "\n",
    "        actual = df['next_close'].iloc[-11:]\n",
    "        predicted = df['predictions'].iloc[-11:]\n",
    "        mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "\n",
    "        df['corrected_prediction'] = df['predictions'] * (1 + mape / 100)\n",
    "        df['MAPE'] = mape\n",
    "        df['signal'], df['confidence'], df['stop_loss'] = trading_strategy(df, mape_threshold, buy_threshold, sell_threshold, stop_loss_percentage)\n",
    "        df['accuracy'] = evaluate_signal_accuracy(df)\n",
    "\n",
    "        last_10_accuracy = calculate_last_10_accuracy(df)\n",
    "\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "        st.write(df[['timestamp', 'close', 'next_close', 'predictions', 'corrected_prediction', 'signal', 'confidence', 'stop_loss', 'accuracy']].tail(11))\n",
    "\n",
    "        st.write(\"Señales de Trading:\")\n",
    "        for index, row in df[['timestamp', 'signal', 'confidence', 'stop_loss', 'accuracy']].tail(11).iterrows():\n",
    "            st.write(f\"Timestamp: {row['timestamp']}, Señal: {row['signal']}, Confianza: {row['confidence']:.2f}, Stop-Loss: {row['stop_loss']}, Exactitud: {row['accuracy']}\")\n",
    "\n",
    "        st.write(f\"Precisión global de las señales en las últimas 10 sesiones: {last_10_accuracy:.2f}%\")\n",
    "        st.write(f\"Error Absoluto Medio Porcentual (MAPE): {mape:.2f}%\")\n",
    "\n",
    "        current_time = datetime.now()\n",
    "        if current_time.minute > 20:\n",
    "            st.warning(\"Faltan menos de 40 minutos para el cierre de la hora actual. Es mejor pedir información en la siguiente hora.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
