{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from binance.client import Client\n",
    "import requests\n",
    "import ta\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import GRU, LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from keras.models import load_model\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "              timestamp    close  next_close   predictions  \\\n",
      "709 2024-05-22 03:00:00  69943.8     69544.7  67996.062500   \n",
      "710 2024-05-22 04:00:00  69544.7     69865.0  67956.585938   \n",
      "711 2024-05-22 05:00:00  69865.0     69842.0  67946.367188   \n",
      "712 2024-05-22 06:00:00  69842.0     69712.7  68041.226562   \n",
      "713 2024-05-22 07:00:00  69712.7     70000.9  68070.742188   \n",
      "714 2024-05-22 08:00:00  70000.9     69990.7  68175.242188   \n",
      "715 2024-05-22 09:00:00  69990.7     70192.1  68266.023438   \n",
      "716 2024-05-22 10:00:00  70192.1     69811.6  68334.335938   \n",
      "717 2024-05-22 11:00:00  69811.6     69638.3  68329.406250   \n",
      "718 2024-05-22 12:00:00  69638.3     69788.3  68338.734375   \n",
      "719 2024-05-22 13:00:00  69788.3         NaN  68221.382812   \n",
      "\n",
      "     corrected_prediction      MAPE    signal    confidence  stop_loss  \\\n",
      "709          69644.161173  2.423815    Vender  4.862078e-03        NaN   \n",
      "710          69603.727772  2.423815   Comprar  6.982752e-04  68153.806   \n",
      "711          69593.261338  2.423815    Vender  2.498820e-03        NaN   \n",
      "712          69690.419929  2.423815    Vender  1.737479e-03        NaN   \n",
      "713          69720.650958  2.423815   Comprar  1.649396e-03  68318.446   \n",
      "714          69827.683844  2.423815    Vender  1.146193e-03        NaN   \n",
      "715          69920.665464  2.423815    Vender  9.468056e-07        NaN   \n",
      "716          69990.633732  2.423815    Vender  2.942147e-03        NaN   \n",
      "717          69985.584558  2.423815   Comprar  2.629058e-03  68415.368   \n",
      "718          69995.138780  2.423815   Comprar  3.398171e-03  68245.534   \n",
      "719          69874.942833  2.423815  Mantener           NaN        NaN   \n",
      "\n",
      "    accuracy  \n",
      "709     True  \n",
      "710     True  \n",
      "711     True  \n",
      "712     True  \n",
      "713     True  \n",
      "714     True  \n",
      "715    False  \n",
      "716     True  \n",
      "717    False  \n",
      "718     True  \n",
      "719      NaN  \n",
      "El porcentaje de acierto en las Ãºltimas 10 sesiones es: 80.00%\n"
     ]
    }
   ],
   "source": [
    "def fetch_latest_data_kraken(symbol, limit):\n",
    "    exchange = ccxt.kraken()\n",
    "    ohlcv = exchange.fetch_ohlcv(symbol, timeframe='1h', limit=limit)\n",
    "    data = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "    data.set_index('timestamp', inplace=True)\n",
    "    return data\n",
    "\n",
    "def initialize_support_resistance(df):\n",
    "    df['support'] = df['low'].rolling(window=30).min()\n",
    "    df['resistance'] = df['high'].rolling(window=30).max()\n",
    "    df['dynamic_support'] = df['low'].rolling(window=5).min()\n",
    "    df['dynamic_resistance'] = df['high'].rolling(window=5).max()\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df['sma_7'] = df['close'].rolling(window=7).mean()\n",
    "    df['ema_7'] = df['close'].ewm(span=7, adjust=False).mean()\n",
    "    df['sma_14'] = df['close'].rolling(window=14).mean()\n",
    "    df['ema_14'] = df['close'].ewm(span=14, adjust=False).mean()\n",
    "    df['sma_21'] = df['close'].rolling(window=21).mean()\n",
    "    df['ema_21'] = df['close'].ewm(span=21, adjust=False).mean()\n",
    "    df['sma_28'] = df['close'].rolling(window=28).mean()\n",
    "    df['ema_28'] = df['close'].ewm(span=28, adjust=False).mean()\n",
    "    df['sma_50'] = df['close'].rolling(window=50).mean()\n",
    "    df['ema_50'] = df['close'].ewm(span=50, adjust=False).mean()\n",
    "    df['sma_100'] = df['close'].rolling(window=100).mean()\n",
    "    df['ema_100'] = df['close'].ewm(span=100, adjust=False).mean()\n",
    "    df['sma_200'] = df['close'].rolling(window=200).mean()\n",
    "    df['ema_200'] = df['close'].ewm(span=200, adjust=False).mean()\n",
    "    df['rsi_14'] = talib.RSI(df['close'], timeperiod=14)\n",
    "    df['macd'], df['macd_signal'], df['macd_diff'] = talib.MACD(df['close'])\n",
    "    df['willr'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['atr_14'] = talib.ATR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['adx'] = talib.ADX(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['cci'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['ichimoku_a'] = (talib.MIN(df['low'], timeperiod=9) + talib.MAX(df['high'], timeperiod=9)) / 2\n",
    "    df['ichimoku_b'] = (talib.MIN(df['low'], timeperiod=26) + talib.MAX(df['high'], timeperiod=26)) / 2\n",
    "    df['momentum_10'] = talib.MOM(df['close'], timeperiod=10)\n",
    "    df['momentum_14'] = talib.MOM(df['close'], timeperiod=14)\n",
    "    df['momentum_20'] = talib.MOM(df['close'], timeperiod=20)\n",
    "    df['momentum_30'] = talib.MOM(df['close'], timeperiod=30)\n",
    "    df['keltner_hband'] = talib.MA((df['high'] + df['low'] + df['close']) / 3 + 2 * df['atr_14'], timeperiod=10)\n",
    "    df['keltner_lband'] = talib.MA((df['high'] + df['low'] + df['close']) / 3 - 2 * df['atr_14'], timeperiod=10)\n",
    "    df['doji'] = talib.CDLDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['engulfing'] = talib.CDLENGULFING(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['hammer'] = talib.CDLHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['inverted_hammer'] = talib.CDLINVERTEDHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['hanging_man'] = talib.CDLHANGINGMAN(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['shooting_star'] = talib.CDLSHOOTINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['morning_star'] = talib.CDLMORNINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['evening_star'] = talib.CDLEVENINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['morning_doji_star'] = talib.CDLMORNINGDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['evening_doji_star'] = talib.CDLEVENINGDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['piercing_line'] = talib.CDLPIERCING(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['dark_cloud_cover'] = talib.CDLDARKCLOUDCOVER(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_white_soldiers'] = talib.CDL3WHITESOLDIERS(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_black_crows'] = talib.CDL3BLACKCROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_inside_up_down'] = talib.CDL3INSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_outside_up_down'] = talib.CDL3OUTSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_stars_in_the_south'] = talib.CDL3STARSINSOUTH(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_advancing_white_soldiers'] = talib.CDLADVANCEBLOCK(df['open'], df['high'], df['low'], df['close'])\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "def create_sequences(X, y, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        xs.append(X[i:i + seq_length])\n",
    "        ys.append(y[i + seq_length])\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "def trading_strategy(df, mape_threshold, buy_threshold, sell_threshold, stop_loss_percentage):\n",
    "    signals = []\n",
    "    confidences = []\n",
    "    stop_losses = []\n",
    "    for i in range(len(df) - 1):\n",
    "        if df['MAPE'].iloc[i] > mape_threshold:\n",
    "            signals.append('No hacer nada')\n",
    "            confidences.append(0)\n",
    "            stop_losses.append(np.nan)\n",
    "        else:\n",
    "            confidence = abs(df['corrected_prediction'].iloc[i + 1] - df['close'].iloc[i]) / df['close'].iloc[i]\n",
    "            confidences.append(confidence)\n",
    "            if df['corrected_prediction'].iloc[i + 1] > df['close'].iloc[i] + buy_threshold:\n",
    "                signals.append('Comprar')\n",
    "                stop_loss = df['close'].iloc[i] * (1 - stop_loss_percentage)\n",
    "                stop_losses.append(stop_loss)\n",
    "            elif df['corrected_prediction'].iloc[i + 1] < df['close'].iloc[i] - sell_threshold:\n",
    "                signals.append('Vender')\n",
    "                stop_losses.append(np.nan)\n",
    "            else:\n",
    "                signals.append('Mantener')\n",
    "                stop_losses.append(np.nan)\n",
    "    signals.append('Mantener')\n",
    "    confidences.append(np.nan)  # Ajustamos para evitar el 0 en la Ãºltima predicciÃ³n\n",
    "    stop_losses.append(np.nan)\n",
    "    return signals, confidences, stop_losses\n",
    "\n",
    "def evaluate_signal_accuracy(df):\n",
    "    accuracies = []\n",
    "    for i in range(len(df) - 1):\n",
    "        if df['signal'].iloc[i] == 'Comprar':\n",
    "            accuracies.append(df['next_close'].iloc[i] > df['close'].iloc[i])\n",
    "        elif df['signal'].iloc[i] == 'Vender':\n",
    "            accuracies.append(df['next_close'].iloc[i] < df['close'].iloc[i])\n",
    "        elif df['signal'].iloc[i] == 'Mantener':\n",
    "            accuracies.append(abs(df['next_close'].iloc[i] - df['close'].iloc[i]) < 0.01 * df['close'].iloc[i])\n",
    "        else:\n",
    "            accuracies.append(np.nan)\n",
    "    accuracies.append(np.nan)  # La Ãºltima fila no tiene siguiente cierre para comparar\n",
    "    return accuracies\n",
    "\n",
    "def calculate_last_10_accuracy(df):\n",
    "    # Trabajar solo con las Ãºltimas 10 filas vÃ¡lidas excluyendo la Ãºltima fila incompleta\n",
    "    df_last_10 = df.iloc[-11:-1] \n",
    "    total_signals = df_last_10['accuracy'].notna().sum()  # Total de seÃ±ales vÃ¡lidas en las Ãºltimas 10 filas\n",
    "    correct_signals = (df_last_10['accuracy'] == True).sum()  # NÃºmero de seÃ±ales correctas en las Ãºltimas 10 filas\n",
    "    return correct_signals / total_signals * 100 if total_signals > 0 else 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    st.title('AplicaciÃ³n de Trading')\n",
    "    symbol = 'BTC/USDT'\n",
    "    limit = 60000\n",
    "    mape_threshold = 3  # Umbral de MAPE para no hacer nada\n",
    "    buy_threshold = 0.01  # Umbral para seÃ±al de compra\n",
    "    sell_threshold = 0.01  # Umbral para seÃ±al de venta\n",
    "    stop_loss_percentage = 0.02  # Stop-loss al 2% del precio de compra\n",
    "\n",
    "    df = fetch_latest_data_kraken(symbol, limit)\n",
    "    df = initialize_support_resistance(df)\n",
    "    df = preprocess_data(df)\n",
    "\n",
    "    df['next_close'] = df['close'].shift(-1)\n",
    "\n",
    "    features = df.drop(columns=['next_close'])\n",
    "    target = df['next_close']\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    target_scaled = scaler.fit_transform(target.values.reshape(-1, 1))\n",
    "\n",
    "    seq_length = 50\n",
    "    X, y = create_sequences(features_scaled, target_scaled, seq_length)\n",
    "\n",
    "    model_path = f'../models/best_model_BTCUSDT.keras'\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # AsegÃºrate de que la forma de entrada es correcta para el modelo\n",
    "    if X.shape[1:] != model.input_shape[1:]:\n",
    "        st.error(f\"Shape mismatch: X shape is {X.shape[1:]}, model expects {model.input_shape[1:]}\")\n",
    "        return\n",
    "\n",
    "    # PredicciÃ³n para las Ãºltimas 11 valores\n",
    "    predictions = []\n",
    "    for i in range(11):\n",
    "        input_data = X[-(11 - i)].reshape(1, seq_length, features_scaled.shape[1])\n",
    "        pred = model.predict(input_data)\n",
    "        predictions.append(scaler.inverse_transform(pred)[0][0])\n",
    "\n",
    "    # Agregar predicciones al DataFrame original para comparaciÃ³n\n",
    "    df['predictions'] = np.nan\n",
    "    df.iloc[-11:, df.columns.get_loc('predictions')] = predictions\n",
    "\n",
    "    # Calcular MAPE\n",
    "    actual = df['next_close'].iloc[-11:]\n",
    "    predicted = df['predictions'].iloc[-11:]\n",
    "    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "\n",
    "    # Ajuste de predicciones basado en MAPE\n",
    "    df['corrected_prediction'] = df['predictions'] * (1 + mape / 100)\n",
    "\n",
    "    # Generar seÃ±ales de trading y stop-loss\n",
    "    df['MAPE'] = mape\n",
    "    df['signal'], df['confidence'], df['stop_loss'] = trading_strategy(df, mape_threshold, buy_threshold, sell_threshold, stop_loss_percentage)\n",
    "\n",
    "    # Evaluar la exactitud de las seÃ±ales\n",
    "    df['accuracy'] = evaluate_signal_accuracy(df)\n",
    "\n",
    "    # Calcular la precisiÃ³n global para las Ãºltimas 10 filas\n",
    "    last_10_accuracy = calculate_last_10_accuracy(df)\n",
    "\n",
    "    # Restablecer el Ã­ndice para que 'timestamp' estÃ© disponible como columna\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Mostrar la tabla en Streamlit\n",
    "    st.write(df[['timestamp', 'close', 'next_close', 'predictions', 'corrected_prediction', 'signal', 'confidence', 'stop_loss', 'accuracy']].tail(11))\n",
    "\n",
    "    # Mostrar seÃ±ales de trading en Streamlit\n",
    "    st.write(\"SeÃ±ales de Trading:\")\n",
    "    for index, row in df[['timestamp', 'signal', 'confidence', 'stop_loss', 'accuracy']].tail(11).iterrows():\n",
    "        st.write(f\"Timestamp: {row['timestamp']}, SeÃ±al: {row['signal']}, Confianza: {row['confidence']:.2f}, Stop-Loss: {row['stop_loss']}, Exactitud: {row['accuracy']}\")\n",
    "\n",
    "    # Mostrar precisiÃ³n global y MAPE\n",
    "    st.write(f\"PrecisiÃ³n global de las seÃ±ales en las Ãºltimas 10 sesiones: {last_10_accuracy:.2f}%\")\n",
    "    st.write(f\"Error Absoluto Medio Porcentual (MAPE): {mape:.2f}%\")\n",
    "\n",
    "    # Advertir si falta poco tiempo para el cierre de la hora\n",
    "    current_time = datetime.now()\n",
    "    if current_time.minute > 20:\n",
    "        st.warning(\"Faltan menos de 40 minutos para el cierre de la hora actual. Es mejor pedir informaciÃ³n en la siguiente hora.\")\n",
    "\n",
    "    # Imprimir las Ãºltimas 11 sesiones con los datos relevantes\n",
    "    print(df[['timestamp', 'close', 'next_close', 'predictions', 'corrected_prediction', 'MAPE', 'signal', 'confidence', 'stop_loss', 'accuracy']].tail(11))\n",
    "\n",
    "    # Imprimir el porcentaje de acierto en las Ãºltimas 10 sesiones\n",
    "    print(f\"El porcentaje de acierto en las Ãºltimas 10 sesiones es: {last_10_accuracy:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 13:49:24.855967: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-22 13:49:24.889621: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-22 13:49:24.889669: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-22 13:49:24.890835: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-22 13:49:24.896699: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-22 13:49:24.897619: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-22 13:49:26.730048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-05-22 13:49:28.299 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/codespace/.local/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-05-22 13:49:28.300 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import ccxt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from keras.models import load_model\n",
    "from datetime import datetime\n",
    "\n",
    "# Definir las funciones necesarias\n",
    "def fetch_latest_data_kraken(symbol, limit):\n",
    "    exchange = ccxt.kraken()\n",
    "    ohlcv = exchange.fetch_ohlcv(symbol, timeframe='1h', limit=limit)\n",
    "    data = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "    data.set_index('timestamp', inplace=True)\n",
    "    return data\n",
    "\n",
    "def initialize_support_resistance(df):\n",
    "    df['support'] = df['low'].rolling(window=30).min()\n",
    "    df['resistance'] = df['high'].rolling(window=30).max()\n",
    "    df['dynamic_support'] = df['low'].rolling(window=5).min()\n",
    "    df['dynamic_resistance'] = df['high'].rolling(window=5).max()\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df['sma_7'] = df['close'].rolling(window=7).mean()\n",
    "    df['ema_7'] = df['close'].ewm(span=7, adjust=False).mean()\n",
    "    df['sma_14'] = df['close'].rolling(window=14).mean()\n",
    "    df['ema_14'] = df['close'].ewm(span=14, adjust=False).mean()\n",
    "    df['sma_21'] = df['close'].rolling(window=21).mean()\n",
    "    df['ema_21'] = df['close'].ewm(span=21, adjust=False).mean()\n",
    "    df['sma_28'] = df['close'].rolling(window=28).mean()\n",
    "    df['ema_28'] = df['close'].ewm(span=28, adjust=False).mean()\n",
    "    df['sma_50'] = df['close'].rolling(window=50).mean()\n",
    "    df['ema_50'] = df['close'].ewm(span=50, adjust=False).mean()\n",
    "    df['sma_100'] = df['close'].rolling(window=100).mean()\n",
    "    df['ema_100'] = df['close'].ewm(span=100, adjust=False).mean()\n",
    "    df['sma_200'] = df['close'].rolling(window=200).mean()\n",
    "    df['ema_200'] = df['close'].ewm(span=200, adjust=False).mean()\n",
    "    df['rsi_14'] = talib.RSI(df['close'], timeperiod=14)\n",
    "    df['macd'], df['macd_signal'], df['macd_diff'] = talib.MACD(df['close'])\n",
    "    df['willr'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['atr_14'] = talib.ATR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['adx'] = talib.ADX(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['cci'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['ichimoku_a'] = (talib.MIN(df['low'], timeperiod=9) + talib.MAX(df['high'], timeperiod=9)) / 2\n",
    "    df['ichimoku_b'] = (talib.MIN(df['low'], timeperiod=26) + talib.MAX(df['high'], timeperiod=26)) / 2\n",
    "    df['momentum_10'] = talib.MOM(df['close'], timeperiod=10)\n",
    "    df['momentum_14'] = talib.MOM(df['close'], timeperiod=14)\n",
    "    df['momentum_20'] = talib.MOM(df['close'], timeperiod=20)\n",
    "    df['momentum_30'] = talib.MOM(df['close'], timeperiod=30)\n",
    "    df['keltner_hband'] = talib.MA((df['high'] + df['low'] + df['close']) / 3 + 2 * df['atr_14'], timeperiod=10)\n",
    "    df['keltner_lband'] = talib.MA((df['high'] + df['low'] + df['close']) / 3 - 2 * df['atr_14'], timeperiod=10)\n",
    "    df['doji'] = talib.CDLDOJI(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['engulfing'] = talib.CDLENGULFING(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['hammer'] = talib.CDLHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['inverted_hammer'] = talib.CDLINVERTEDHAMMER(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['hanging_man'] = talib.CDLHANGINGMAN(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['shooting_star'] = talib.CDLSHOOTINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['morning_star'] = talib.CDLMORNINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['evening_star'] = talib.CDLEVENINGSTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['morning_doji_star'] = talib.CDLMORNINGDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['evening_doji_star'] = talib.CDLEVENINGDOJISTAR(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['piercing_line'] = talib.CDLPIERCING(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['dark_cloud_cover'] = talib.CDLDARKCLOUDCOVER(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_white_soldiers'] = talib.CDL3WHITESOLDIERS(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_black_crows'] = talib.CDL3BLACKCROWS(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_inside_up_down'] = talib.CDL3INSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_outside_up_down'] = talib.CDL3OUTSIDE(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_stars_in_the_south'] = talib.CDL3STARSINSOUTH(df['open'], df['high'], df['low'], df['close'])\n",
    "    df['three_advancing_white_soldiers'] = talib.CDLADVANCEBLOCK(df['open'], df['high'], df['low'], df['close'])\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "def create_sequences(X, y, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        xs.append(X[i:i + seq_length])\n",
    "        ys.append(y[i + seq_length])\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "def trading_strategy(df, mape_threshold, buy_threshold, sell_threshold, stop_loss_percentage):\n",
    "    signals = []\n",
    "    confidences = []\n",
    "    stop_losses = []\n",
    "    for i in range(len(df) - 1):\n",
    "        if df['MAPE'].iloc[i] > mape_threshold:\n",
    "            signals.append('No hacer nada')\n",
    "            confidences.append(0)\n",
    "            stop_losses.append(np.nan)\n",
    "        else:\n",
    "            confidence = abs(df['corrected_prediction'].iloc[i + 1] - df['close'].iloc[i]) / df['close'].iloc[i]\n",
    "            confidences.append(confidence)\n",
    "            if df['corrected_prediction'].iloc[i + 1] > df['close'].iloc[i] + buy_threshold:\n",
    "                signals.append('Comprar')\n",
    "                stop_loss = df['close'].iloc[i] * (1 - stop_loss_percentage)\n",
    "                stop_losses.append(stop_loss)\n",
    "            elif df['corrected_prediction'].iloc[i + 1] < df['close'].iloc[i] - sell_threshold:\n",
    "                signals.append('Vender')\n",
    "                stop_losses.append(np.nan)\n",
    "            else:\n",
    "                signals.append('Mantener')\n",
    "                stop_losses.append(np.nan)\n",
    "    signals.append('Mantener')\n",
    "    confidences.append(np.nan)\n",
    "    stop_losses.append(np.nan)\n",
    "    return signals, confidences, stop_losses\n",
    "\n",
    "def evaluate_signal_accuracy(df):\n",
    "    accuracies = []\n",
    "    for i in range(len(df) - 1):\n",
    "        if df['signal'].iloc[i] == 'Comprar':\n",
    "            accuracies.append(df['next_close'].iloc[i] > df['close'].iloc[i])\n",
    "        elif df['signal'].iloc[i] == 'Vender':\n",
    "            accuracies.append(df['next_close'].iloc[i] < df['close'].iloc[i])\n",
    "        elif df['signal'].iloc[i] == 'Mantener':\n",
    "            accuracies.append(abs(df['next_close'].iloc[i] - df['close'].iloc[i]) < 0.01 * df['close'].iloc[i])\n",
    "        else:\n",
    "            accuracies.append(np.nan)\n",
    "    accuracies.append(np.nan)\n",
    "    return accuracies\n",
    "\n",
    "def calculate_last_10_accuracy(df):\n",
    "    df_last_10 = df.iloc[-11:-1]\n",
    "    total_signals = df_last_10['accuracy'].notna().sum()\n",
    "    correct_signals = (df_last_10['accuracy'] == True).sum()\n",
    "    return correct_signals / total_signals * 100 if total_signals > 0 else 0\n",
    "\n",
    "# Interfaz de Streamlit\n",
    "def main():\n",
    "    st.title('AplicaciÃ³n de Trading para Criptomonedas')\n",
    "    st.sidebar.header('ParÃ¡metros')\n",
    "    \n",
    "    crypto_symbol = st.sidebar.selectbox('Selecciona la criptomoneda', ['BTC/USDT', 'ETH/USDT', 'XRP/USDT', 'LTC/USDT'])\n",
    "    limit = st.sidebar.number_input('NÃºmero de registros (60000 recomendado)', min_value=1000, max_value=100000, value=60000)\n",
    "    mape_threshold = st.sidebar.slider('Umbral de MAPE (%)', 0, 10, 3)\n",
    "    buy_threshold = st.sidebar.slider('Umbral de compra (%)', 0.0, 5.0, 0.01)\n",
    "    sell_threshold = st.sidebar.slider('Umbral de venta (%)', 0.0, 5.0, 0.01)\n",
    "    stop_loss_percentage = st.sidebar.slider('Stop-loss (%)', 0.0, 10.0, 2.0)\n",
    "    seq_length = st.sidebar.slider('Longitud de la secuencia', 1, 100, 50)\n",
    "\n",
    "    if st.sidebar.button('Ejecutar PredicciÃ³n'):\n",
    "        df = fetch_latest_data_kraken(crypto_symbol, limit)\n",
    "        df = initialize_support_resistance(df)\n",
    "        df = preprocess_data(df)\n",
    "\n",
    "        df['next_close'] = df['close'].shift(-1)\n",
    "\n",
    "        features = df.drop(columns=['next_close'])\n",
    "        target = df['next_close']\n",
    "\n",
    "        scaler = RobustScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "        target_scaled = scaler.fit_transform(target.values.reshape(-1, 1))\n",
    "\n",
    "        X, y = create_sequences(features_scaled, target_scaled, seq_length)\n",
    "\n",
    "        model_path = f'../models/best_model_{crypto_symbol.replace(\"/\", \"\")}.keras'\n",
    "        model = load_model(model_path)\n",
    "\n",
    "        if X.shape[1:] != model.input_shape[1:]:\n",
    "            st.error(f\"Shape mismatch: X shape is {X.shape[1:]}, model expects {model.input_shape[1:]}\")\n",
    "            return\n",
    "\n",
    "        predictions = []\n",
    "        for i in range(11):\n",
    "            input_data = X[-(11 - i)].reshape(1, seq_length, features_scaled.shape[1])\n",
    "            pred = model.predict(input_data)\n",
    "            predictions.append(scaler.inverse_transform(pred)[0][0])\n",
    "\n",
    "        df['predictions'] = np.nan\n",
    "        df.iloc[-11:, df.columns.get_loc('predictions')] = predictions\n",
    "\n",
    "        actual = df['next_close'].iloc[-11:]\n",
    "        predicted = df['predictions'].iloc[-11:]\n",
    "        mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "\n",
    "        df['corrected_prediction'] = df['predictions'] * (1 + mape / 100)\n",
    "        df['MAPE'] = mape\n",
    "        df['signal'], df['confidence'], df['stop_loss'] = trading_strategy(df, mape_threshold, buy_threshold, sell_threshold, stop_loss_percentage)\n",
    "        df['accuracy'] = evaluate_signal_accuracy(df)\n",
    "\n",
    "        last_10_accuracy = calculate_last_10_accuracy(df)\n",
    "\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "        st.write(df[['timestamp', 'close', 'next_close', 'predictions', 'corrected_prediction', 'signal', 'confidence', 'stop_loss', 'accuracy']].tail(11))\n",
    "\n",
    "        st.write(\"SeÃ±ales de Trading:\")\n",
    "        for index, row in df[['timestamp', 'signal', 'confidence', 'stop_loss', 'accuracy']].tail(11).iterrows():\n",
    "            st.write(f\"Timestamp: {row['timestamp']}, SeÃ±al: {row['signal']}, Confianza: {row['confidence']:.2f}, Stop-Loss: {row['stop_loss']}, Exactitud: {row['accuracy']}\")\n",
    "\n",
    "        st.write(f\"PrecisiÃ³n global de las seÃ±ales en las Ãºltimas 10 sesiones: {last_10_accuracy:.2f}%\")\n",
    "        st.write(f\"Error Absoluto Medio Porcentual (MAPE): {mape:.2f}%\")\n",
    "\n",
    "        current_time = datetime.now()\n",
    "        if current_time.minute > 20:\n",
    "            st.warning(\"Faltan menos de 40 minutos para el cierre de la hora actual. Es mejor pedir informaciÃ³n en la siguiente hora.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
